Checking if all services are running...

Checking py-fastapi at http://localhost:3103/json... ✅ OK
Checking node-express at http://localhost:3100/json... ✅ OK
Checking go-gin at http://localhost:3102/json... ✅ OK
Checking buntal at http://localhost:3101/json... ✅ OK

✅ All services are running and responding!

Starting benchmark with 100 requests per service...

Benchmarking py-fastapi... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking node-express... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking go-gin... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking buntal... 20/100 40/100 60/100 80/100 100/100 Done!

╔════════════════════════════════════════════════════════════════════════════╗
║                           BENCHMARK RESULTS                                ║
╠════════════════════════════════════════════════════════════════════════════╣
║ Machine: Darwin arm64 | Apple M1 Pro | 16.0 GB                             ║
║ Date: 2025-06-02 19:36:50 WIB                                              ║
║ Requests per service: 100                                                  ║
╠═══════════════╦════════════════════════╦═══════════════════════════════════╣
║   Service     ║   Avg Latency (sec)    ║      RPS (req/sec)                ║
╠═══════════════╬════════════════════════╬═══════════════════════════════════╣
║ py-fastapi    ║               0.001037 ║                            963.98 ║
║ node-express  ║               0.000728 ║                           1373.12 ║
║ go-gin        ║               0.000453 ║                           2206.43 ║
║ buntal        ║               0.000448 ║                           2232.29 ║
╚═══════════════╩════════════════════════╩═══════════════════════════════════╝

🏆 Best Performance: buntal with 2232.29 RPS

