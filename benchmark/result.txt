Checking if all services are running...

Checking py-fastapi at http://localhost:3103/json... ✅ OK
Checking node-express at http://localhost:3100/json... ✅ OK
Checking go-gin at http://localhost:3102/json... ✅ OK
Checking elysia at http://localhost:3104/json... ✅ OK
Checking buntal at http://localhost:3101/json... ✅ OK

✅ All services are running and responding!

Starting benchmark with 100 requests per service...

Benchmarking py-fastapi... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking node-express... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking go-gin... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking elysia... 20/100 40/100 60/100 80/100 100/100 Done!
Benchmarking buntal... 20/100 40/100 60/100 80/100 100/100 Done!

╔════════════════════════════════════════════════════════════════════════════╗
║                           BENCHMARK RESULTS                                ║
╠════════════════════════════════════════════════════════════════════════════╣
║ Machine: Darwin arm64 | Apple M1 Pro | 16.0 GB                             ║
║ Date: 2025-06-02 19:58:32 WIB                                              ║
║ Requests per service: 100                                                  ║
╠═══════════════╦════════════════════════╦═══════════════════════════════════╣
║   Service     ║   Avg Latency (sec)    ║      RPS (req/sec)                ║
╠═══════════════╬════════════════════════╬═══════════════════════════════════╣
║ py-fastapi    ║               0.001124 ║                            889.43 ║
║ node-express  ║               0.000705 ║                           1418.64 ║
║ go-gin        ║               0.000491 ║                           2035.50 ║
║ elysia        ║               0.000458 ║                           2183.79 ║
║ buntal        ║               0.000458 ║                           2182.88 ║
╚═══════════════╩════════════════════════╩═══════════════════════════════════╝

🏆 Best Performance: elysia with 2183.79 RPS
🥈 2nd: buntal with 2182.88 RPS

